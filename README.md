# README for LLM-Generated Text Detection Using Ensemble Methods

This project focuses on detecting whether a text passage was generated by a Large Language Model (LLM). It leverages a combination of feature engineering, tokenization techniques, and an ensemble of machine learning models for accurate classification.

## Key Components

### 1. Data Preparation

**Data Sources:**
- `test_essays.csv`: Contains the text essays to be classified as either human-written or LLM-generated.
- `train_v2_drcat_02.csv` (optional): Contains labeled training data with text and corresponding labels.

**Preprocessing:**
- Exclusion of specific prompts from the training data to avoid bias.
- Removal of duplicate text entries.
- Identification and counting of high and medium frequency keywords in the text.

### 2. Feature Engineering

**Tokenization:**
- Utilizes a byte-pair encoding (BPE) tokenizer trained on the test data to create a vocabulary of subword tokens.

**TF-IDF Vectorization:**
- Transforms tokenized texts into TF-IDF vectors to capture the importance of words and phrases in the text.
- Applies ngrams (3-5 words) to incorporate contextual information.

### 3. Model Development

**Ensemble Model:**
- Combines a Multinomial Naive Bayes (MNB) classifier, Stochastic Gradient Descent (SGD) classifier, LightGBM (LGBM) classifier, and CatBoost classifier.
- Uses voting with weighted probabilities to produce the final predictions.

**Hyperparameter Optimization:**
- Employs parameter grids and optimization techniques for each base model within the ensemble.

### 4. Training and Prediction

**Training:**
- If training data is available, fits the ensemble model on the TF-IDF vectors and corresponding labels.

**Prediction:**
- Generates probabilities for each test essay being LLM-generated.

**Post-processing:**
- Adjusts probabilities based on the presence of high or medium-frequency keywords.
- Clips probabilities to ensure they fall within the valid range (0 to 1).

### 5. Submission

**Formatting:**
- Prepares a submission file with essay IDs and predicted probabilities.

## Additional Notes

- **Edge Cases:** The `edge_cases.csv` file may contain information about edge cases or outliers that could affect the model's performance.
- **Ensemble Approach:** The use of multiple models and weighted voting aims to improve robustness and generalization of the classifier.
